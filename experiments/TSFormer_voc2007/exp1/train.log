model training time: 2022-10-16 21:45:42
model configuration: 
Namespace(
    model: TSFormer
    data: voc2007
    seed: 1
    lr: 1.1e-05
    batch_size: 16
    mode: part
    optimizer: AdamW
    lr_scheduler: ReduceLROnPlateau
    weight_decay: 0.0001
    start_depth: 4
    img_size: 448
    num_heads: 1
    embed_type: bert
    loss_fn: bce
    gamma_pos: 0.0
    gamma_neg: 1.0
    clip: 0.05
    max_epoch: 100
    warmup_epoch: 2
    topk: 3
    threshold: 0.5
    pretrained: True
    restore_exp: None
    gpus: 3
    train_path: data/voc2007/train.txt
    test_path: data/voc2007/test.txt
    label_path: data/voc2007/label.txt
    embed_path: data/voc2007/bert.npy
    ignore_path: data/voc2007/ignore.npy
    num_classes: 20
    exp_dir: experiments/TSFormer_voc2007/exp7
    log_path: experiments/TSFormer_voc2007/exp7/train.log
    ckpt_dir: experiments/TSFormer_voc2007/exp7/checkpoints
    ckpt_best_path: experiments/TSFormer_voc2007/exp7/checkpoints/best_model.pth
    ckpt_latest_path: experiments/TSFormer_voc2007/exp7/checkpoints/latest_model.pth
)
Compose(
    RandomHorizontalFlip(p=0.5)
    RandomResizedCrop(size=(448, 448), scale=(0.7, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)
    Random Augment Policy
    Resize(size=(448, 448), interpolation=bilinear, max_size=None, antialias=None)
    ToTensor()
)
Compose(
    Resize(size=(448, 448), interpolation=bilinear, max_size=None, antialias=None)
    ToTensor()
)
Resized position embedding: torch.Size([1, 197, 768]) to torch.Size([1, 785, 768])
Position embedding grid-size from [14, 14] to (28, 28)
total parameters: 188154255
TRAIN [epoch 0] loss: 0.818478 lr:0.0000000 time:1.4305
TRAIN [epoch 0] loss: 0.470335 lr:0.0000001 time:0.4705
TRAIN [epoch 0] loss: 0.232572 lr:0.0000002 time:0.4713
TRAIN [epoch 0] loss: 0.235518 lr:0.0000003 time:0.4733
TRAIN [epoch 0] loss: 0.247454 lr:0.0000004 time:0.4762
TRAIN [epoch 0] loss: 0.215821 lr:0.0000005 time:0.4764
TRAIN [epoch 0] loss: 0.170171 lr:0.0000005 time:0.4713
Validation [epoch 0] mAP: 0.5665
TRAIN [epoch 1] loss: 0.156803 lr:0.0000006 time:0.4682
TRAIN [epoch 1] loss: 0.153793 lr:0.0000007 time:0.4682
TRAIN [epoch 1] loss: 0.091869 lr:0.0000008 time:0.4688
TRAIN [epoch 1] loss: 0.083792 lr:0.0000009 time:0.4682
TRAIN [epoch 1] loss: 0.049496 lr:0.0000010 time:0.4762
TRAIN [epoch 1] loss: 0.042198 lr:0.0000011 time:0.4692
Validation [epoch 1] mAP: 0.8972
TRAIN [epoch 2] loss: 0.073066 lr:0.0000011 time:0.4742
TRAIN [epoch 2] loss: 0.082144 lr:0.0000011 time:0.4695
TRAIN [epoch 2] loss: 0.053143 lr:0.0000011 time:0.4720
TRAIN [epoch 2] loss: 0.018847 lr:0.0000011 time:0.4704
TRAIN [epoch 2] loss: 0.025687 lr:0.0000011 time:0.4685
TRAIN [epoch 2] loss: 0.042185 lr:0.0000011 time:0.4713
Validation [epoch 2] mAP: 0.9573
TRAIN [epoch 3] loss: 0.027735 lr:0.0000011 time:0.4671
TRAIN [epoch 3] loss: 0.032515 lr:0.0000011 time:0.4681
TRAIN [epoch 3] loss: 0.015737 lr:0.0000011 time:0.4677
TRAIN [epoch 3] loss: 0.011734 lr:0.0000011 time:0.4697
TRAIN [epoch 3] loss: 0.015164 lr:0.0000011 time:0.4692
TRAIN [epoch 3] loss: 0.044891 lr:0.0000011 time:0.4690
Validation [epoch 3] mAP: 0.9655
TRAIN [epoch 4] loss: 0.006319 lr:0.0000011 time:0.4671
TRAIN [epoch 4] loss: 0.019703 lr:0.0000011 time:0.4678
TRAIN [epoch 4] loss: 0.012731 lr:0.0000011 time:0.4679
TRAIN [epoch 4] loss: 0.022427 lr:0.0000011 time:0.4691
TRAIN [epoch 4] loss: 0.014531 lr:0.0000011 time:0.4676
TRAIN [epoch 4] loss: 0.050895 lr:0.0000011 time:0.4719
Validation [epoch 4] mAP: 0.9676
TRAIN [epoch 5] loss: 0.035830 lr:0.0000011 time:0.4672
TRAIN [epoch 5] loss: 0.019571 lr:0.0000011 time:0.4681
TRAIN [epoch 5] loss: 0.017707 lr:0.0000011 time:0.4690
TRAIN [epoch 5] loss: 0.022844 lr:0.0000011 time:0.4680
TRAIN [epoch 5] loss: 0.026979 lr:0.0000011 time:0.4689
TRAIN [epoch 5] loss: 0.023606 lr:0.0000011 time:0.4696
Validation [epoch 5] mAP: 0.9691
TRAIN [epoch 6] loss: 0.015106 lr:0.0000011 time:0.4666
TRAIN [epoch 6] loss: 0.033600 lr:0.0000011 time:0.4683
TRAIN [epoch 6] loss: 0.025909 lr:0.0000011 time:0.4687
TRAIN [epoch 6] loss: 0.010416 lr:0.0000011 time:0.4700
TRAIN [epoch 6] loss: 0.012745 lr:0.0000011 time:0.4709
TRAIN [epoch 6] loss: 0.019444 lr:0.0000011 time:0.4694
Validation [epoch 6] mAP: 0.9689
TRAIN [epoch 7] loss: 0.008833 lr:0.0000011 time:0.4716
TRAIN [epoch 7] loss: 0.048450 lr:0.0000011 time:0.4725
TRAIN [epoch 7] loss: 0.012389 lr:0.0000011 time:0.4748
TRAIN [epoch 7] loss: 0.040158 lr:0.0000011 time:0.4728
TRAIN [epoch 7] loss: 0.002270 lr:0.0000011 time:0.4723
TRAIN [epoch 7] loss: 0.007947 lr:0.0000011 time:0.4745
Validation [epoch 7] mAP: 0.9698
TRAIN [epoch 8] loss: 0.016886 lr:0.0000011 time:0.4672
TRAIN [epoch 8] loss: 0.010424 lr:0.0000011 time:0.4676
TRAIN [epoch 8] loss: 0.022981 lr:0.0000011 time:0.4726
TRAIN [epoch 8] loss: 0.032247 lr:0.0000011 time:0.4694
TRAIN [epoch 8] loss: 0.009418 lr:0.0000011 time:0.4692
TRAIN [epoch 8] loss: 0.016968 lr:0.0000011 time:0.4700
Validation [epoch 8] mAP: 0.9683
TRAIN [epoch 9] loss: 0.008734 lr:0.0000011 time:0.4687
TRAIN [epoch 9] loss: 0.003609 lr:0.0000011 time:0.4699
TRAIN [epoch 9] loss: 0.004920 lr:0.0000011 time:0.4681
TRAIN [epoch 9] loss: 0.038374 lr:0.0000011 time:0.4687
TRAIN [epoch 9] loss: 0.006057 lr:0.0000011 time:0.4696
TRAIN [epoch 9] loss: 0.024240 lr:0.0000011 time:0.4703
Validation [epoch 9] mAP: 0.9687
TRAIN [epoch 10] loss: 0.016694 lr:0.0000001 time:0.4689
TRAIN [epoch 10] loss: 0.028453 lr:0.0000001 time:0.4684
TRAIN [epoch 10] loss: 0.010508 lr:0.0000001 time:0.4700
TRAIN [epoch 10] loss: 0.005767 lr:0.0000001 time:0.4709
TRAIN [epoch 10] loss: 0.022954 lr:0.0000001 time:0.4695
TRAIN [epoch 10] loss: 0.010434 lr:0.0000001 time:0.4700
Validation [epoch 10] mAP: 0.9688
TRAIN [epoch 11] loss: 0.002588 lr:0.0000001 time:0.4686
TRAIN [epoch 11] loss: 0.008021 lr:0.0000001 time:0.4688
TRAIN [epoch 11] loss: 0.007213 lr:0.0000001 time:0.4695
TRAIN [epoch 11] loss: 0.006396 lr:0.0000001 time:0.4698
TRAIN [epoch 11] loss: 0.027201 lr:0.0000001 time:0.4693
TRAIN [epoch 11] loss: 0.002166 lr:0.0000001 time:0.4702
Validation [epoch 11] mAP: 0.9689

training over, best validation score: 0.9698286529143108 mAP
